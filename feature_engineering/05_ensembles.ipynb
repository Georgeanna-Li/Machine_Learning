{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Ensembles\n",
    "\n",
    "<blockquote>\n",
    "The interests of truth require a diversity of opinions.    \n",
    "    \n",
    "by John Stuart Mill\n",
    "</blockquote>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import string\n",
    "import sys\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"code/.\")\n",
    "\n",
    "from plotting_functions import *\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "- Use `scikit-learn`'s `RandomForestClassifier` and explain its main hyperparameters. \n",
    "- Explain the sources of randomness in random forest algorithm. \n",
    "- Use other tree-based models such as as `XGBoost`, `LGBM` and `CatBoost`.  \n",
    "- Broadly explain ensemble classifier approaches, in particular model averaging and stacking.\n",
    "- Use `scikit-learn` implementations of these ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation [[video](https://youtu.be/8litm1H7DLo)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ensembles** are models that combine multiple machine learning models to create more powerful models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Netflix prize\n",
    "\n",
    "![](img/netflix.png)\n",
    "\n",
    "[Source](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Most of the winning solutions for Kaggle competitions involve some kind of ensembling. For example: \n",
    "\n",
    "<center>\n",
    "<img src=\"img/fraud_detection_kaggle.png\" width=\"600\" height=\"600\">\n",
    "</center>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Key idea: Groups can often make better decisions than individuals, especially when group members are diverse enough. \n",
    "\n",
    "[The Wisdom of Crowds](http://wisdomofcrowds.blogspot.com/2009/12/introduction-part-i.html)\n",
    "\n",
    "<center>\n",
    "<img src=\"img/wisdom_of_crowds.jpg\" width=\"300\" height=\"300\">\n",
    "</center>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tree-based ensemble models \n",
    "- A number of ensemble models in ML literature.\n",
    "- Most successful ones on a variety of datasets are tree-based models. \n",
    "- We'll briefly talk about two such models: \n",
    "    - Random forests\n",
    "    - Gradient boosted trees\n",
    "- We'll also talk about averaging and stacking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tree-based models \n",
    "\n",
    "- Decision trees models are \n",
    "    - Interpretable \n",
    "    - They can capture non-linear relationships\n",
    "    - They don't require scaling of the data and theoretically can work with categorical features. \n",
    "- But single decision trees are likely to overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Key idea: Combine multiple trees to build stronger models.\n",
    "- These kinds of models are extremely popular in industry and machine learning competitions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data\n",
    "\n",
    "- Let's work with [the adult census data set](https://www.kaggle.com/uciml/adult-census-income). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>26</td>\n",
       "      <td>Private</td>\n",
       "      <td>256263</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19777</th>\n",
       "      <td>24</td>\n",
       "      <td>Private</td>\n",
       "      <td>170277</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10781</th>\n",
       "      <td>36</td>\n",
       "      <td>Private</td>\n",
       "      <td>75826</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32240</th>\n",
       "      <td>22</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>24395</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>31</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>356689</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt     education  education.num  \\\n",
       "5514    26    Private  256263       HS-grad              9   \n",
       "19777   24    Private  170277       HS-grad              9   \n",
       "10781   36    Private   75826     Bachelors             13   \n",
       "32240   22  State-gov   24395  Some-college             10   \n",
       "9876    31  Local-gov  356689     Bachelors             13   \n",
       "\n",
       "           marital.status      occupation   relationship   race     sex  \\\n",
       "5514        Never-married    Craft-repair  Not-in-family  White    Male   \n",
       "19777       Never-married   Other-service  Not-in-family  White  Female   \n",
       "10781            Divorced    Adm-clerical      Unmarried  White  Female   \n",
       "32240  Married-civ-spouse    Adm-clerical           Wife  White  Female   \n",
       "9876   Married-civ-spouse  Prof-specialty        Husband  White    Male   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "5514              0             0              25  United-States  <=50K  \n",
       "19777             0             0              35  United-States  <=50K  \n",
       "10781             0             0              40  United-States  <=50K  \n",
       "32240             0             0              20  United-States  <=50K  \n",
       "9876              0             0              40  United-States  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_df_large = pd.read_csv(\"data/adult.csv\")\n",
    "train_df, test_df = train_test_split(adult_df_large, test_size=0.2, random_state=42)\n",
    "train_df_nan = train_df.replace(\"?\", np.NaN)\n",
    "test_df_nan = test_df.replace(\"?\", np.NaN)\n",
    "train_df_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = [\"age\", \"fnlwgt\", \"capital.gain\", \"capital.loss\", \"hours.per.week\"]\n",
    "categorical_features = [\n",
    "    \"workclass\",\n",
    "    \"marital.status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"native.country\",\n",
    "]\n",
    "ordinal_features = [\"education\"]\n",
    "binary_features = [\"sex\"]\n",
    "drop_features = [\"race\", \"education.num\"]\n",
    "target_column = \"income\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "education_levels = [\n",
    "    \"Preschool\",\n",
    "    \"1st-4th\",\n",
    "    \"5th-6th\",\n",
    "    \"7th-8th\",\n",
    "    \"9th\",\n",
    "    \"10th\",\n",
    "    \"11th\",\n",
    "    \"12th\",\n",
    "    \"HS-grad\",\n",
    "    \"Prof-school\",\n",
    "    \"Assoc-voc\",\n",
    "    \"Assoc-acdm\",\n",
    "    \"Some-college\",\n",
    "    \"Bachelors\",\n",
    "    \"Masters\",\n",
    "    \"Doctorate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "assert set(education_levels) == set(train_df[\"education\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "ordinal_transformer = make_pipeline(\n",
    "    OrdinalEncoder(categories=[education_levels], dtype=int)\n",
    ")\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    ")\n",
    "\n",
    "binary_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(drop=\"if_binary\", dtype=int),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (ordinal_transformer, ordinal_features),\n",
    "    (binary_transformer, binary_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_df_nan.drop(columns=[target_column])\n",
    "y_train = train_df_nan[target_column]\n",
    "\n",
    "X_test = test_df_nan.drop(columns=[target_column])\n",
    "y_test = test_df_nan[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Do we have class imbalance? \n",
    "\n",
    "- There is class imbalance. But without any context, both classes seem equally important. \n",
    "- Let's use accuracy as our metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    0.757985\n",
       ">50K     0.242015\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan[\"income\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "scoring_metric = \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's store all the results in a dictionary called `results`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  `DummyClassifier` baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy=\"stratified\")\n",
    "results[\"Dummy\"] = mean_std_cross_val_scores(\n",
    "    dummy, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `DecisionTreeClassifier` baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Let's try decision tree classifier on our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.029 (+/- 0.021)</td>\n",
       "      <td>0.012 (+/- 0.004)</td>\n",
       "      <td>0.634 (+/- 0.006)</td>\n",
       "      <td>0.632 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.278 (+/- 0.020)</td>\n",
       "      <td>0.029 (+/- 0.003)</td>\n",
       "      <td>0.813 (+/- 0.003)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fit_time         score_time         test_score  \\\n",
       "Dummy          0.029 (+/- 0.021)  0.012 (+/- 0.004)  0.634 (+/- 0.006)   \n",
       "Decision tree  0.278 (+/- 0.020)  0.029 (+/- 0.003)  0.813 (+/- 0.003)   \n",
       "\n",
       "                     train_score  \n",
       "Dummy          0.632 (+/- 0.002)  \n",
       "Decision tree  1.000 (+/- 0.000)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_dt = make_pipeline(preprocessor, DecisionTreeClassifier(random_state=123))\n",
    "results[\"Decision tree\"] = mean_std_cross_val_scores(\n",
    "    pipe_dt, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    ")\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree is clearly overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### General idea\n",
    "\n",
    "- A single decision tree is likely to overfit\n",
    "- Use a collection of diverse decision trees\n",
    "- Each tree overfits on some part of the data but we can reduce overfitting by averaging the results \n",
    "    - can be shown mathematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `RandomForestClassifier` \n",
    "\n",
    "- Before understanding the details let's first try it out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.029 (+/- 0.021)</td>\n",
       "      <td>0.012 (+/- 0.004)</td>\n",
       "      <td>0.634 (+/- 0.006)</td>\n",
       "      <td>0.632 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.278 (+/- 0.020)</td>\n",
       "      <td>0.029 (+/- 0.003)</td>\n",
       "      <td>0.813 (+/- 0.003)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forests</th>\n",
       "      <td>2.184 (+/- 1.304)</td>\n",
       "      <td>0.112 (+/- 0.025)</td>\n",
       "      <td>0.857 (+/- 0.004)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fit_time         score_time         test_score  \\\n",
       "Dummy           0.029 (+/- 0.021)  0.012 (+/- 0.004)  0.634 (+/- 0.006)   \n",
       "Decision tree   0.278 (+/- 0.020)  0.029 (+/- 0.003)  0.813 (+/- 0.003)   \n",
       "Random forests  2.184 (+/- 1.304)  0.112 (+/- 0.025)  0.857 (+/- 0.004)   \n",
       "\n",
       "                      train_score  \n",
       "Dummy           0.632 (+/- 0.002)  \n",
       "Decision tree   1.000 (+/- 0.000)  \n",
       "Random forests  1.000 (+/- 0.000)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe_rf = make_pipeline(\n",
    "    preprocessor, RandomForestClassifier(random_state=123, n_jobs=-1)\n",
    ")\n",
    "results[\"Random forests\"] = mean_std_cross_val_scores(\n",
    "    pipe_rf, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    ")\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The validation scores are better although it seems likes we are still overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do they work? \n",
    "\n",
    "- Decide how many decision trees we want to build\n",
    "    - can control with `n_estimators` hyperparameter \n",
    "- `fit` a diverse set of that many decision trees by **injecting randomness** in the model construction\n",
    "- `predict` by voting (classification) or averaging (regression) of predictions given by individual models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inject randomness in the classifier construction\n",
    "\n",
    "To ensure that the trees in the random forest are different we inject randomness in two ways:  \n",
    "\n",
    "1. Data: **Build each tree on a bootstrap sample** (i.e., a sample drawn **with replacement** from the training set)\n",
    "2. Features: **At each node, select a random subset of features** (controlled by `max_features` in `scikit-learn`) and look for the best possible test involving one of these features   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An example of a bootstrap samples\n",
    "\n",
    "Suppose this is your original dataset: [1,2,3,4]\n",
    "- a sample drawn with replacement: [1,1,3,4]\n",
    "- a sample drawn with replacement: [3,2,2,2]\n",
    "- a sample drawn with replacement: [1,2,4,4]\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{seealso}\n",
    "There is also something called [`ExtraTreesClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html), where we add more randomness by consider a random subset of features at each split and **random threshold**. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The random forests classifier \n",
    "\n",
    "- Create a collection (ensemble) of trees. Grow each tree on an independent bootstrap sample from the data.\n",
    "- At each node:\n",
    "    - Randomly select a subset of features out of all features (independently for each node).\n",
    "    - Find the best split on the selected features. \n",
    "    - Grow the trees to maximum depth.\n",
    "    \n",
    "- Prediction time    \n",
    "    - Vote the trees to get predictions for new example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example \n",
    "\n",
    "- Let's create a random forest with 3 estimators. \n",
    "- I'm using `max_depth=2` for easy visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pipe_rf_demo = make_pipeline(\n",
    "    preprocessor, RandomForestClassifier(max_depth=2, n_estimators=3, random_state=123)\n",
    ")\n",
    "pipe_rf_demo.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let's get the feature names of transformed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                  Pipeline(steps=[('standardscaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['age', 'fnlwgt',\n",
       "                                                   'capital.gain',\n",
       "                                                   'capital.loss',\n",
       "                                                   'hours.per.week']),\n",
       "                                                 ('pipeline-2',\n",
       "                                                  Pipeline(steps=[('ordinalencoder',\n",
       "                                                                   OrdinalEncoder(categories=[['Preschool',\n",
       "                                                                                               '1st-4th',\n",
       "                                                                                               '5th-6th',\n",
       "                                                                                               '7th-8th',\n",
       "                                                                                               '9th',\n",
       "                                                                                               '10th',\n",
       "                                                                                               '11th',\n",
       "                                                                                               '12th',\n",
       "                                                                                               'HS...\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehotencoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  ['workclass',\n",
       "                                                   'marital.status',\n",
       "                                                   'occupation', 'relationship',\n",
       "                                                   'native.country']),\n",
       "                                                 ('drop', 'drop',\n",
       "                                                  ['race', 'education.num'])])),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(max_depth=2, n_estimators=3,\n",
       "                                        random_state=123))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf_demo # you can always look into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'fnlwgt',\n",
       " 'capital.gain',\n",
       " 'capital.loss',\n",
       " 'hours.per.week',\n",
       " 'education',\n",
       " 'sex',\n",
       " 'x0_Federal-gov',\n",
       " 'x0_Local-gov',\n",
       " 'x0_Never-worked']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = (\n",
    "    numeric_features\n",
    "    + ordinal_features\n",
    "    + binary_features\n",
    "    + list(\n",
    "        pipe_rf_demo.named_steps[\"columntransformer\"]\n",
    "        .named_transformers_[\"pipeline-4\"]  #refer to the place where we define the pipeline, it's the 4th\n",
    "        .named_steps[\"onehotencoder\"]\n",
    "        .get_feature_names_out()\n",
    "    )\n",
    ")\n",
    "feature_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let's sample a test example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  ['<=50K' '>50K']\n",
      "Prediction by random forest:  ['<=50K']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.038780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>0.528836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital.gain</th>\n",
       "      <td>0.270073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital.loss</th>\n",
       "      <td>-0.217680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours.per.week</th>\n",
       "      <td>0.768789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4_Trinadad&amp;Tobago</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4_United-States</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4_Vietnam</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4_Yugoslavia</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4_missing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "age                -0.038780\n",
       "fnlwgt              0.528836\n",
       "capital.gain        0.270073\n",
       "capital.loss       -0.217680\n",
       "hours.per.week      0.768789\n",
       "...                      ...\n",
       "x4_Trinadad&Tobago  0.000000\n",
       "x4_United-States    1.000000\n",
       "x4_Vietnam          0.000000\n",
       "x4_Yugoslavia       0.000000\n",
       "x4_missing          0.000000\n",
       "\n",
       "[86 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example = X_test.sample(1)\n",
    "print(\"Classes: \", pipe_rf_demo.classes_)\n",
    "print(\"Prediction by random forest: \", pipe_rf_demo.predict(test_example))\n",
    "transformed_example = preprocessor.transform(test_example)\n",
    "pd.DataFrame(data=transformed_example.flatten(), index=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We can look at different trees created by random forest. \n",
    "- Note that each tree looks at different set of features and slightly different data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tree 1\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.49.1 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"446pt\" height=\"192pt\"\n",
       " viewBox=\"0.00 0.00 446.00 192.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 188)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-188 442,-188 442,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"320,-184 118,-184 118,-146 320,-146 320,-184\"/>\n",
       "<text text-anchor=\"middle\" x=\"219\" y=\"-168.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x1_Married&#45;civ&#45;spouse &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"219\" y=\"-153.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"206,-110 34,-110 34,-72 206,-72 206,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"120\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x1_Never&#45;married &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"120\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M194.02,-145.83C181.71,-136.88 166.69,-125.96 153.41,-116.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155.12,-113.21 144.97,-110.16 151,-118.88 155.12,-113.21\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.87\" y=\"-131.16\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"412,-110 224,-110 224,-72 412,-72 412,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"318\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x2_Exec&#45;managerial &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"318\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243.98,-145.83C256.29,-136.88 271.31,-125.96 284.59,-116.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"287,-118.88 293.03,-110.16 282.88,-113.21 287,-118.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"289.13\" y=\"-131.16\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"84,-36 0,-36 0,0 84,0 84,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"42\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99.91,-71.72C90.27,-62.94 78.6,-52.31 68.27,-42.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.43,-40.15 60.68,-36 65.72,-45.32 70.43,-40.15\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"186,-36 102,-36 102,0 186,0 186,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"144\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M126.18,-71.72C128.86,-63.8 132.04,-54.38 134.97,-45.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.37,-46.6 138.25,-36 131.73,-44.36 138.37,-46.6\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"336,-36 252,-36 252,0 336,0 336,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"294\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M311.82,-71.72C309.14,-63.8 305.96,-54.38 303.03,-45.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"306.27,-44.36 299.75,-36 299.63,-46.6 306.27,-44.36\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"438,-36 354,-36 354,0 438,0 438,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"396\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M338.09,-71.72C347.73,-62.94 359.4,-52.31 369.73,-42.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"372.28,-45.32 377.32,-36 367.57,-40.15 372.28,-45.32\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f932af9dc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction [0.]\n",
      "\n",
      "\n",
      "Tree 2\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.49.1 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"424pt\" height=\"192pt\"\n",
       " viewBox=\"0.00 0.00 424.00 192.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 188)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-188 420,-188 420,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"271.5,-184 142.5,-184 142.5,-146 271.5,-146 271.5,-184\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-168.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">education &lt;= 12.5</text>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-153.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"193,-110 67,-110 67,-72 193,-72 193,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"130\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x0_Private &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"130\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M187.57,-145.83C178.27,-137.13 166.98,-126.58 156.87,-117.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.12,-114.44 149.42,-110.16 154.34,-119.55 159.12,-114.44\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.26\" y=\"-131.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"359,-110 211,-110 211,-72 359,-72 359,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"285\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x3_Unmarried &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"285\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M226.68,-145.83C236.11,-137.13 247.54,-126.58 257.78,-117.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"260.35,-119.52 265.32,-110.16 255.6,-114.37 260.35,-119.52\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.32\" y=\"-131.44\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"84,-36 0,-36 0,0 84,0 84,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"42\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.34,-71.72C96.25,-62.77 82.77,-51.9 70.95,-42.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"73.06,-39.56 63.07,-36 68.66,-45.01 73.06,-39.56\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"186,-36 102,-36 102,0 186,0 186,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"144\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M133.61,-71.72C135.15,-63.89 136.98,-54.59 138.68,-45.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.15,-46.49 140.65,-36 135.28,-45.14 142.15,-46.49\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"314,-36 230,-36 230,0 314,0 314,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"272\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M281.65,-71.72C280.22,-63.89 278.52,-54.59 276.94,-45.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.36,-45.21 275.11,-36 273.47,-46.47 280.36,-45.21\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"416,-36 332,-36 332,0 416,0 416,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M307.92,-71.72C319.13,-62.77 332.76,-51.9 344.72,-42.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"347.05,-44.98 352.69,-36 342.69,-39.5 347.05,-44.98\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f9346f9ad00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction [0.]\n",
      "\n",
      "\n",
      "Tree 3\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.49.1 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"420pt\" height=\"192pt\"\n",
       " viewBox=\"0.00 0.00 420.00 192.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 188)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-188 416,-188 416,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"291,-184 119,-184 119,-146 291,-146 291,-184\"/>\n",
       "<text text-anchor=\"middle\" x=\"205\" y=\"-168.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x1_Never&#45;married &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"205\" y=\"-153.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"205,-110 59,-110 59,-72 205,-72 205,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">capital.gain &lt;= 0.531</text>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M186.58,-145.83C177.85,-137.22 167.27,-126.79 157.76,-117.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.99,-114.69 150.42,-110.16 155.08,-119.68 159.99,-114.69\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.59\" y=\"-131.46\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"335,-110 223,-110 223,-72 335,-72 335,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"279\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">fnlwgt &lt;= 7.478</text>\n",
       "<text text-anchor=\"middle\" x=\"279\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223.67,-145.83C232.52,-137.22 243.25,-126.79 252.89,-117.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"255.61,-119.64 260.33,-110.16 250.72,-114.63 255.61,-119.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"259.99\" y=\"-131.46\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"84,-36 0,-36 0,0 84,0 84,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"42\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.82,-71.72C97.48,-62.77 83.7,-51.9 71.61,-42.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"73.57,-39.45 63.55,-36 69.24,-44.94 73.57,-39.45\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"186,-36 102,-36 102,0 186,0 186,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"144\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135.09,-71.72C136.41,-63.89 137.99,-54.59 139.44,-45.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.91,-46.45 141.13,-36 136.01,-45.28 142.91,-46.45\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"310,-36 226,-36 226,0 310,0 310,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"268\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M276.17,-71.72C274.95,-63.89 273.51,-54.59 272.18,-45.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"275.62,-45.35 270.63,-36 268.71,-46.42 275.62,-45.35\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"412,-36 328,-36 328,0 412,0 412,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"370\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M302.43,-71.72C313.9,-62.77 327.84,-51.9 340.06,-42.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"342.48,-44.91 348.21,-36 338.17,-39.4 342.48,-44.91\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f9346f9aaf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction [0.]\n"
     ]
    }
   ],
   "source": [
    "for i, tree in enumerate(\n",
    "    pipe_rf_demo.named_steps[\"randomforestclassifier\"].estimators_\n",
    "):\n",
    "    print(\"\\n\\nTree\", i + 1)\n",
    "    display(display_tree(feature_names, tree))\n",
    "    print(\"prediction\", tree.predict(preprocessor.transform(test_example)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some important hyperparameters:\n",
    "\n",
    "- `n_estimators`: number of decision trees (higher = more complexity)\n",
    "- `max_depth`: max depth of each decision tree (higher = more complexity)\n",
    "- `max_features`: the number of features you get to look at each split (higher = more complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Random forests: number of trees (`n_estimators`) and the fundamental tradeoff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_num_tree_plot(\n",
    "    preprocessor, X_train, y_train, X_test, y_test, [1, 5, 10, 25, 50, 100, 200, 500]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Number of trees and fundamental trade-off\n",
    "\n",
    "- Above: seems like we're beating the fundamental \"tradeoff\" by increasing training score and not decreasing validation score much.\n",
    "- This is the promise of ensembles, though it's not guaranteed to work so nicely.\n",
    "\n",
    "More trees are always better! We pick less trees for speed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Strengths and weaknesses\n",
    "\n",
    "- Usually one of the best performing off-the-shelf classifiers without heavy tuning of hyperparameters\n",
    "- Don't require scaling of data \n",
    "- Less likely to overfit \n",
    "- Slower than decision trees because we are fitting multiple trees but can easily parallelize training because all trees are independent of each other \n",
    "- In general, able to capture a much broader picture of the data compared to a single decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Weaknesses\n",
    "\n",
    "- Require more memory \n",
    "- Hard to interpret\n",
    "- Tend not to perform well on high dimensional sparse data such as text data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{important}\n",
    "Make sure to set the `random_state` for reproducibility. Changing the `random_state` can have a big impact on the model and the results due to the random nature of these models. Having more trees can get you a more robust estimate. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{seealso}\n",
    "[The original random forests paper](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf) by Leo Breiman. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient boosted trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another popular and effective class of tree-based models is gradient boosted trees. \n",
    "\n",
    "- No randomization.\n",
    "- The key idea is combining many simple models called weak learners to create a strong learner. \n",
    "- They combine multiple shallow (depth 1 to 5) decision trees  \n",
    "- They build trees in a **serial manner**, where each tree tries to correct the mistakes of the previous one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Important hyperparameters\n",
    "\n",
    "- `n_estimators`\n",
    "    - control the number of trees to build\n",
    "- `learning_rate`\n",
    "    - controls how strongly each tree tries to correct the mistakes of the previous trees\n",
    "    - higher learning rate means each tree can make stronger corrections, which means more complex model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll not go into the details. We'll look at brief examples of using the following three gradient boosted tree models. \n",
    "\n",
    "- [XGBoost](https://xgboost.readthedocs.io/en/latest/)\n",
    "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html)\n",
    "- [CatBoost](https://catboost.ai/docs/concepts/python-quickstart.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [XGBoost](https://xgboost.ai/about) \n",
    "\n",
    "- Not part of `sklearn` but has similar interface. \n",
    "- Install it in your conda environment: `conda install -c conda-forge xgboost`\n",
    "- Supports missing values\n",
    "- GPU training, networked parallel training\n",
    "- Supports sparse data\n",
    "- Typically better scores than random forests    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [LightGBM](https://lightgbm.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not part of `sklearn` but has similar interface. \n",
    "- Install it in your conda environment: `conda install -c conda-forge lightgbm`\n",
    "- Small model size\n",
    "- Faster \n",
    "- Typically better scores than random forests    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [CatBoost](https://catboost.ai/)\n",
    "\n",
    "- Not part of `sklearn` but has similar interface. \n",
    "- Install it in your conda environment: `conda install -c conda-forge catboost`\n",
    "- Usually better scores but slower compared to `XGBoost` and `LightGBM`     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipe_lr = make_pipeline(\n",
    "    preprocessor, LogisticRegression(max_iter=2000, random_state=123)\n",
    ")\n",
    "pipe_dt = make_pipeline(preprocessor, DecisionTreeClassifier(random_state=123))\n",
    "pipe_rf = make_pipeline(preprocessor, RandomForestClassifier(random_state=123))\n",
    "pipe_xgb = make_pipeline(\n",
    "    preprocessor, XGBClassifier(random_state=123, eval_metric=\"logloss\", verbosity=0)\n",
    ")\n",
    "pipe_lgbm = make_pipeline(preprocessor, LGBMClassifier(random_state=123))\n",
    "pipe_catboost = make_pipeline(\n",
    "    preprocessor, CatBoostClassifier(verbose=0, random_state=123)\n",
    ")\n",
    "classifiers = {\n",
    "    \"logistic regression\": pipe_lr,\n",
    "    \"decision tree\": pipe_dt,\n",
    "    \"random forest\": pipe_rf,\n",
    "    \"XGBoost\": pipe_xgb,\n",
    "    \"LightGBM\": pipe_lgbm,\n",
    "    \"CatBoost\": pipe_catboost,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy=\"stratified\")\n",
    "results[\"Dummy\"] = mean_std_cross_val_scores(\n",
    "    dummy, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for (name, model) in classifiers.items():\n",
    "    results[name] = mean_std_cross_val_scores(\n",
    "        model, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.015 (+/- 0.002)</td>\n",
       "      <td>0.011 (+/- 0.001)</td>\n",
       "      <td>0.632 (+/- 0.008)</td>\n",
       "      <td>0.633 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>3.919 (+/- 0.436)</td>\n",
       "      <td>0.074 (+/- 0.009)</td>\n",
       "      <td>0.850 (+/- 0.005)</td>\n",
       "      <td>0.851 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.542 (+/- 0.199)</td>\n",
       "      <td>0.049 (+/- 0.010)</td>\n",
       "      <td>0.813 (+/- 0.003)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>3.168 (+/- 0.494)</td>\n",
       "      <td>0.206 (+/- 0.015)</td>\n",
       "      <td>0.857 (+/- 0.004)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>7.407 (+/- 1.594)</td>\n",
       "      <td>0.080 (+/- 0.019)</td>\n",
       "      <td>0.870 (+/- 0.003)</td>\n",
       "      <td>0.909 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.407 (+/- 0.020)</td>\n",
       "      <td>0.075 (+/- 0.006)</td>\n",
       "      <td>0.871 (+/- 0.004)</td>\n",
       "      <td>0.892 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>7.460 (+/- 0.421)</td>\n",
       "      <td>0.199 (+/- 0.029)</td>\n",
       "      <td>0.872 (+/- 0.003)</td>\n",
       "      <td>0.900 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fit_time         score_time         test_score  \\\n",
       "Dummy                0.015 (+/- 0.002)  0.011 (+/- 0.001)  0.632 (+/- 0.008)   \n",
       "logistic regression  3.919 (+/- 0.436)  0.074 (+/- 0.009)  0.850 (+/- 0.005)   \n",
       "decision tree        0.542 (+/- 0.199)  0.049 (+/- 0.010)  0.813 (+/- 0.003)   \n",
       "random forest        3.168 (+/- 0.494)  0.206 (+/- 0.015)  0.857 (+/- 0.004)   \n",
       "XGBoost              7.407 (+/- 1.594)  0.080 (+/- 0.019)  0.870 (+/- 0.003)   \n",
       "LightGBM             0.407 (+/- 0.020)  0.075 (+/- 0.006)  0.871 (+/- 0.004)   \n",
       "CatBoost             7.460 (+/- 0.421)  0.199 (+/- 0.029)  0.872 (+/- 0.003)   \n",
       "\n",
       "                           train_score  \n",
       "Dummy                0.633 (+/- 0.003)  \n",
       "logistic regression  0.851 (+/- 0.001)  \n",
       "decision tree        1.000 (+/- 0.000)  \n",
       "random forest        1.000 (+/- 0.000)  \n",
       "XGBoost              0.909 (+/- 0.002)  \n",
       "LightGBM             0.892 (+/- 0.000)  \n",
       "CatBoost             0.900 (+/- 0.001)  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Some observations**\n",
    "- Keep in mind all these results are with default hyperparameters\n",
    "- Ideally we would carry out hyperparameter optimization for all of them and then compare the results. \n",
    "- We are using a particular scoring metric (accuracy in this case)\n",
    "- We are scaling numeric features but it shouldn't matter for these tree-based models. \n",
    "- Look at the std. Doesn't look very high. \n",
    "    - The scores look more or less stable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.015 (+/- 0.002)</td>\n",
       "      <td>0.011 (+/- 0.001)</td>\n",
       "      <td>0.632 (+/- 0.008)</td>\n",
       "      <td>0.633 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>3.919 (+/- 0.436)</td>\n",
       "      <td>0.074 (+/- 0.009)</td>\n",
       "      <td>0.850 (+/- 0.005)</td>\n",
       "      <td>0.851 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.542 (+/- 0.199)</td>\n",
       "      <td>0.049 (+/- 0.010)</td>\n",
       "      <td>0.813 (+/- 0.003)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>3.168 (+/- 0.494)</td>\n",
       "      <td>0.206 (+/- 0.015)</td>\n",
       "      <td>0.857 (+/- 0.004)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>7.407 (+/- 1.594)</td>\n",
       "      <td>0.080 (+/- 0.019)</td>\n",
       "      <td>0.870 (+/- 0.003)</td>\n",
       "      <td>0.909 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.407 (+/- 0.020)</td>\n",
       "      <td>0.075 (+/- 0.006)</td>\n",
       "      <td>0.871 (+/- 0.004)</td>\n",
       "      <td>0.892 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>7.460 (+/- 0.421)</td>\n",
       "      <td>0.199 (+/- 0.029)</td>\n",
       "      <td>0.872 (+/- 0.003)</td>\n",
       "      <td>0.900 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fit_time         score_time         test_score  \\\n",
       "Dummy                0.015 (+/- 0.002)  0.011 (+/- 0.001)  0.632 (+/- 0.008)   \n",
       "logistic regression  3.919 (+/- 0.436)  0.074 (+/- 0.009)  0.850 (+/- 0.005)   \n",
       "decision tree        0.542 (+/- 0.199)  0.049 (+/- 0.010)  0.813 (+/- 0.003)   \n",
       "random forest        3.168 (+/- 0.494)  0.206 (+/- 0.015)  0.857 (+/- 0.004)   \n",
       "XGBoost              7.407 (+/- 1.594)  0.080 (+/- 0.019)  0.870 (+/- 0.003)   \n",
       "LightGBM             0.407 (+/- 0.020)  0.075 (+/- 0.006)  0.871 (+/- 0.004)   \n",
       "CatBoost             7.460 (+/- 0.421)  0.199 (+/- 0.029)  0.872 (+/- 0.003)   \n",
       "\n",
       "                           train_score  \n",
       "Dummy                0.633 (+/- 0.003)  \n",
       "logistic regression  0.851 (+/- 0.001)  \n",
       "decision tree        1.000 (+/- 0.000)  \n",
       "random forest        1.000 (+/- 0.000)  \n",
       "XGBoost              0.909 (+/- 0.002)  \n",
       "LightGBM             0.892 (+/- 0.000)  \n",
       "CatBoost             0.900 (+/- 0.001)  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Decision trees and random forests overfit\n",
    "    - Other models do not seem to overfit much. \n",
    "- Fit times\n",
    "    - Decision trees are fast but not very accurate\n",
    "    - LightGBM is faster than decision trees and more accurate! \n",
    "    - CatBoost fit time is highest followed by random forests.  \n",
    "    - There is not much difference between the validation scores of XGBoost, LightGBM, and CatBoost but it is about 48x slower than LightGBM!\n",
    "    - XGBoost and LightGBM are faster and more accurate than random forest!    \n",
    "- Scores times  \n",
    "    - Prediction times are much smaller in all cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What model should I use?\n",
    "\n",
    "**Simple answer**\n",
    "- Whichever gets the highest CV score, but meanwhile make sure that you're not overusing the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Interpretability**\n",
    "- This is an area of growing interest and concern in ML.\n",
    "- How important is interpretability for you? \n",
    "- In the next notebook we'll talk about interpretability of non-linear models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Speed/code maintenance**\n",
    "- Other considerations could be speed (fit and/or predict), maintainability of the code.\n",
    "\n",
    "Finally, you could use all of them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Averaging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Earlier we looked at a bunch of classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['logistic regression', 'decision tree', 'random forest', 'XGBoost', 'LightGBM', 'CatBoost'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use all these models and let them vote during prediction time? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "averaging_model = VotingClassifier(\n",
    "    list(classifiers.items()), voting=\"soft\"\n",
    ")  # need the list() here for cross-validation to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")  # global setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# averaging_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `VotingClassifier` will take a _vote_ using the predictions of the constituent classifier pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Main parameter: `voting`\n",
    "- `voting='hard'` \n",
    "    - it uses the output of `predict` and actually votes.\n",
    "- `voting='soft'`\n",
    "    - with `voting='soft'` it averages the output of `predict_proba` and then thresholds / takes the larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The choice depends on whether you trust `predict_proba` from your base classifiers - if so, it's nice to access that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "averaging_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What happens when you `fit` a `VotingClassifier`?\n",
    "    - It will fit all constituent models.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "It seems sklearn requires us to actually call `fit` on the `VotingClassifier`, instead of passing in pre-fit models. This is an implementation choice rather than a conceptual limitation.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at particular test examples where `income` is \">50k\" (y=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_g50k = (\n",
    "    test_df.query(\"income == '>50K'\").sample(4, random_state=2).drop(columns=[\"income\"])\n",
    ")\n",
    "test_l50k = (\n",
    "    test_df.query(\"income == '<=50K'\")\n",
    "    .sample(4, random_state=2)\n",
    "    .drop(columns=[\"income\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaging_model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are the predictions given by the voting model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Voting classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Voting classifier\n",
       "0              >50K\n",
       "1              >50K\n",
       "2              >50K\n",
       "3             <=50K"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"Voting classifier\": averaging_model.predict(test_g50k)}\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For hard voting, these are the votes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Voting classifier</th>\n",
       "      <th>logistic regression</th>\n",
       "      <th>decision tree</th>\n",
       "      <th>random forest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Voting classifier  logistic regression  decision tree  random forest  \\\n",
       "0              >50K                    1              1              1   \n",
       "1              >50K                    1              1              1   \n",
       "2              >50K                    1              0              1   \n",
       "3             <=50K                    0              0              0   \n",
       "\n",
       "   XGBoost  LightGBM  CatBoost  \n",
       "0        1         1         1  \n",
       "1        1         1         1  \n",
       "2        1         1         1  \n",
       "3        0         0         0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = {\n",
    "    name: classifier.predict(test_g50k)\n",
    "    for name, classifier in averaging_model.named_estimators_.items()\n",
    "}\n",
    "data.update(r1)\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For soft voting, these are the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Voting classifier</th>\n",
       "      <th>logistic regression</th>\n",
       "      <th>decision tree</th>\n",
       "      <th>random forest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.998319</td>\n",
       "      <td>0.998124</td>\n",
       "      <td>0.998798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>0.581470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.699329</td>\n",
       "      <td>0.712771</td>\n",
       "      <td>0.732028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>0.503162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.681060</td>\n",
       "      <td>0.715427</td>\n",
       "      <td>0.679881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0.112658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.210991</td>\n",
       "      <td>0.190440</td>\n",
       "      <td>0.232039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Voting classifier  logistic regression  decision tree  random forest  \\\n",
       "0              >50K             1.000000            1.0           1.00   \n",
       "1              >50K             0.581470            1.0           0.69   \n",
       "2              >50K             0.503162            0.0           0.63   \n",
       "3             <=50K             0.112658            0.0           0.43   \n",
       "\n",
       "    XGBoost  LightGBM  CatBoost  \n",
       "0  0.998319  0.998124  0.998798  \n",
       "1  0.699329  0.712771  0.732028  \n",
       "2  0.681060  0.715427  0.679881  \n",
       "3  0.210991  0.190440  0.232039  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = {\n",
    "    name: classifier.predict_proba(test_g50k)[:, 1]\n",
    "    for name, classifier in averaging_model.named_estimators_.items()\n",
    "}\n",
    "\n",
    "data.update(r2)\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Aside: the probability scores from `DecisionTreeClassifier` are pretty bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how well this model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "results[\"Voting\"] = mean_std_cross_val_scores(averaging_model, \n",
    "                                              X_train, y_train, \n",
    "                                              return_train_score=True, \n",
    "                                              scoring=scoring_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.015 (+/- 0.002)</td>\n",
       "      <td>0.011 (+/- 0.001)</td>\n",
       "      <td>0.632 (+/- 0.008)</td>\n",
       "      <td>0.633 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>3.919 (+/- 0.436)</td>\n",
       "      <td>0.074 (+/- 0.009)</td>\n",
       "      <td>0.850 (+/- 0.005)</td>\n",
       "      <td>0.851 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.542 (+/- 0.199)</td>\n",
       "      <td>0.049 (+/- 0.010)</td>\n",
       "      <td>0.813 (+/- 0.003)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>3.168 (+/- 0.494)</td>\n",
       "      <td>0.206 (+/- 0.015)</td>\n",
       "      <td>0.857 (+/- 0.004)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>7.407 (+/- 1.594)</td>\n",
       "      <td>0.080 (+/- 0.019)</td>\n",
       "      <td>0.870 (+/- 0.003)</td>\n",
       "      <td>0.909 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.407 (+/- 0.020)</td>\n",
       "      <td>0.075 (+/- 0.006)</td>\n",
       "      <td>0.871 (+/- 0.004)</td>\n",
       "      <td>0.892 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>7.460 (+/- 0.421)</td>\n",
       "      <td>0.199 (+/- 0.029)</td>\n",
       "      <td>0.872 (+/- 0.003)</td>\n",
       "      <td>0.900 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting</th>\n",
       "      <td>18.925 (+/- 0.636)</td>\n",
       "      <td>0.663 (+/- 0.081)</td>\n",
       "      <td>0.868 (+/- 0.003)</td>\n",
       "      <td>0.959 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               fit_time         score_time         test_score  \\\n",
       "Dummy                 0.015 (+/- 0.002)  0.011 (+/- 0.001)  0.632 (+/- 0.008)   \n",
       "logistic regression   3.919 (+/- 0.436)  0.074 (+/- 0.009)  0.850 (+/- 0.005)   \n",
       "decision tree         0.542 (+/- 0.199)  0.049 (+/- 0.010)  0.813 (+/- 0.003)   \n",
       "random forest         3.168 (+/- 0.494)  0.206 (+/- 0.015)  0.857 (+/- 0.004)   \n",
       "XGBoost               7.407 (+/- 1.594)  0.080 (+/- 0.019)  0.870 (+/- 0.003)   \n",
       "LightGBM              0.407 (+/- 0.020)  0.075 (+/- 0.006)  0.871 (+/- 0.004)   \n",
       "CatBoost              7.460 (+/- 0.421)  0.199 (+/- 0.029)  0.872 (+/- 0.003)   \n",
       "Voting               18.925 (+/- 0.636)  0.663 (+/- 0.081)  0.868 (+/- 0.003)   \n",
       "\n",
       "                           train_score  \n",
       "Dummy                0.633 (+/- 0.003)  \n",
       "logistic regression  0.851 (+/- 0.001)  \n",
       "decision tree        1.000 (+/- 0.000)  \n",
       "random forest        1.000 (+/- 0.000)  \n",
       "XGBoost              0.909 (+/- 0.002)  \n",
       "LightGBM             0.892 (+/- 0.000)  \n",
       "CatBoost             0.900 (+/- 0.001)  \n",
       "Voting               0.959 (+/- 0.001)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that here we didn't do much better than our best classifier :(. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try removing decision tree classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_ndt = classifiers.copy()\n",
    "del classifiers_ndt[\"decision tree\"]\n",
    "averaging_model_ndt = VotingClassifier(\n",
    "    list(classifiers_ndt.items()), voting=\"soft\"\n",
    ")  # need the list() here for cross_val to work!\n",
    "\n",
    "results[\"Voting_ndt\"] = mean_std_cross_val_scores(\n",
    "    averaging_model_ndt,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    return_train_score=True,\n",
    "    scoring=scoring_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.015 (+/- 0.002)</td>\n",
       "      <td>0.011 (+/- 0.001)</td>\n",
       "      <td>0.632 (+/- 0.008)</td>\n",
       "      <td>0.633 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>3.919 (+/- 0.436)</td>\n",
       "      <td>0.074 (+/- 0.009)</td>\n",
       "      <td>0.850 (+/- 0.005)</td>\n",
       "      <td>0.851 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.542 (+/- 0.199)</td>\n",
       "      <td>0.049 (+/- 0.010)</td>\n",
       "      <td>0.813 (+/- 0.003)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>3.168 (+/- 0.494)</td>\n",
       "      <td>0.206 (+/- 0.015)</td>\n",
       "      <td>0.857 (+/- 0.004)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>7.407 (+/- 1.594)</td>\n",
       "      <td>0.080 (+/- 0.019)</td>\n",
       "      <td>0.870 (+/- 0.003)</td>\n",
       "      <td>0.909 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.407 (+/- 0.020)</td>\n",
       "      <td>0.075 (+/- 0.006)</td>\n",
       "      <td>0.871 (+/- 0.004)</td>\n",
       "      <td>0.892 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>7.460 (+/- 0.421)</td>\n",
       "      <td>0.199 (+/- 0.029)</td>\n",
       "      <td>0.872 (+/- 0.003)</td>\n",
       "      <td>0.900 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting</th>\n",
       "      <td>18.925 (+/- 0.636)</td>\n",
       "      <td>0.663 (+/- 0.081)</td>\n",
       "      <td>0.868 (+/- 0.003)</td>\n",
       "      <td>0.959 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_ndt</th>\n",
       "      <td>16.971 (+/- 0.467)</td>\n",
       "      <td>0.569 (+/- 0.018)</td>\n",
       "      <td>0.872 (+/- 0.003)</td>\n",
       "      <td>0.922 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               fit_time         score_time         test_score  \\\n",
       "Dummy                 0.015 (+/- 0.002)  0.011 (+/- 0.001)  0.632 (+/- 0.008)   \n",
       "logistic regression   3.919 (+/- 0.436)  0.074 (+/- 0.009)  0.850 (+/- 0.005)   \n",
       "decision tree         0.542 (+/- 0.199)  0.049 (+/- 0.010)  0.813 (+/- 0.003)   \n",
       "random forest         3.168 (+/- 0.494)  0.206 (+/- 0.015)  0.857 (+/- 0.004)   \n",
       "XGBoost               7.407 (+/- 1.594)  0.080 (+/- 0.019)  0.870 (+/- 0.003)   \n",
       "LightGBM              0.407 (+/- 0.020)  0.075 (+/- 0.006)  0.871 (+/- 0.004)   \n",
       "CatBoost              7.460 (+/- 0.421)  0.199 (+/- 0.029)  0.872 (+/- 0.003)   \n",
       "Voting               18.925 (+/- 0.636)  0.663 (+/- 0.081)  0.868 (+/- 0.003)   \n",
       "Voting_ndt           16.971 (+/- 0.467)  0.569 (+/- 0.018)  0.872 (+/- 0.003)   \n",
       "\n",
       "                           train_score  \n",
       "Dummy                0.633 (+/- 0.003)  \n",
       "logistic regression  0.851 (+/- 0.001)  \n",
       "decision tree        1.000 (+/- 0.000)  \n",
       "random forest        1.000 (+/- 0.000)  \n",
       "XGBoost              0.909 (+/- 0.002)  \n",
       "LightGBM             0.892 (+/- 0.000)  \n",
       "CatBoost             0.900 (+/- 0.001)  \n",
       "Voting               0.959 (+/- 0.001)  \n",
       "Voting_ndt           0.922 (+/- 0.001)  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still the averaging scores are not better than the best performing model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- It didn't happen here but how could the average do better than the best model???\n",
    "  - From the perspective of the best estimator (in this case CatBoost), why are you adding on worse estimators??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's how this can work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Example | log reg    | rand forest    | cat boost    | Averaged model |\n",
    "|--------|--------|--------|---------|---------------|\n",
    "|  1     | âœ…    |   âœ…    | âŒ     | âœ…âœ…âŒ=>âœ…  |\n",
    "|  2     | âœ…    |   âŒ    | âœ…     | âœ…âŒâœ…=>âœ…  |\n",
    "|  3     | âŒ    |   âœ…    | âœ…     | âŒâœ…âœ…=>âœ…  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In short, as long as the different models make different mistakes, this can work.\n",
    "- Probably in our case, **we didn't have enough diversity.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why not always do this?\n",
    "\n",
    "1. `fit`/`predict` time.\n",
    "2. Reduction in interpretability.\n",
    "3. Reduction in code maintainability (e.g. Netflix prize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What kind of estimators can we combine? \n",
    "\n",
    "- You can combine \n",
    "    - completely different estimators, or similar estimators.\n",
    "    - estimators trained on different samples.\n",
    "    - estimators with different hyperparameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Note\n",
    "\n",
    "1. We can get poorer scores with averaging compared to a single model. \n",
    "2. Random forest is kind of an averaging model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- Another type of ensemble is stacking.\n",
    "- Instead of averaging the outputs of each estimator, use their outputs as _inputs to another model_(and that's our final estimator).\n",
    "- By default for classification, it uses logistic regression.\n",
    "  - We don't need a complex model here necessarily, more of a weighted average.\n",
    "  - The features going into the logistic regression are the classifier outputs, _not_ the original features!\n",
    "  - So the number of coefficients = the number of base estimators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code starts to get too slow here; so we'll remove CatBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_nocat = classifiers.copy()\n",
    "del classifiers_nocat[\"CatBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = StackingClassifier(list(classifiers_nocat.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stacking_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What's going on in here? \n",
    "\n",
    "- It is doing cross-validation by itself by default (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html))\n",
    "\n",
    "> Note that estimators_ are fitted on the full X while final_estimator_ is trained using cross-validated predictions of the base estimators using cross_val_predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is the input features (X) to the meta-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sample = train_df.sample(4, random_state=2).drop(columns=[\"income\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Voting classifier</th>\n",
       "      <th>logistic regression</th>\n",
       "      <th>decision tree</th>\n",
       "      <th>random forest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>logistic regression_pred</th>\n",
       "      <th>decision tree_pred</th>\n",
       "      <th>random forest_pred</th>\n",
       "      <th>XGBoost_pred</th>\n",
       "      <th>LightGBM_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.998319</td>\n",
       "      <td>0.998124</td>\n",
       "      <td>0.998798</td>\n",
       "      <td>0.566138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.249272</td>\n",
       "      <td>0.433701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>0.581470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.699329</td>\n",
       "      <td>0.712771</td>\n",
       "      <td>0.732028</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.007360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>0.503162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.681060</td>\n",
       "      <td>0.715427</td>\n",
       "      <td>0.679881</td>\n",
       "      <td>0.138868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.046355</td>\n",
       "      <td>0.080048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0.112658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.210991</td>\n",
       "      <td>0.190440</td>\n",
       "      <td>0.232039</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.003702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Voting classifier  logistic regression  decision tree  random forest  \\\n",
       "0              >50K             1.000000            1.0           1.00   \n",
       "1              >50K             0.581470            1.0           0.69   \n",
       "2              >50K             0.503162            0.0           0.63   \n",
       "3             <=50K             0.112658            0.0           0.43   \n",
       "\n",
       "    XGBoost  LightGBM  CatBoost  logistic regression_pred  decision tree_pred  \\\n",
       "0  0.998319  0.998124  0.998798                  0.566138                 0.0   \n",
       "1  0.699329  0.712771  0.732028                  0.000986                 0.0   \n",
       "2  0.681060  0.715427  0.679881                  0.138868                 0.0   \n",
       "3  0.210991  0.190440  0.232039                  0.004720                 0.0   \n",
       "\n",
       "   random forest_pred  XGBoost_pred  LightGBM_pred  \n",
       "0                0.12      0.249272       0.433701  \n",
       "1                0.00      0.005498       0.007360  \n",
       "2                0.05      0.046355       0.080048  \n",
       "3                0.00      0.002433       0.003702  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3 = {\n",
    "    name + \"_pred\": pipe.predict_proba(valid_sample)[:, 1]\n",
    "    for (name, pipe) in stacking_model.named_estimators_.items()\n",
    "}\n",
    "data.update(r3)\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Our meta-model is logistic regression (which it is by default).\n",
    "- Let's look at the learned coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>3.683991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>2.023106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.763360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.218966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>-0.011349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Coefficient\n",
       "LightGBM                3.683991\n",
       "XGBoost                 2.023106\n",
       "logistic regression     0.763360\n",
       "random forest           0.218966\n",
       "decision tree          -0.011349"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=stacking_model.final_estimator_.coef_.flatten(),   # we want to look at the final estimator\n",
    "    index=classifiers_nocat.keys(),\n",
    "    columns=[\"Coefficient\"],\n",
    ").sort_values(\"Coefficient\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.31969548])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.final_estimator_.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- It seems that the LightGBM is being trusted the most. \n",
    "- It's funny that it has given a negative coefficient to decision tree. \n",
    "    - Our meta model doesn't trust decision tree model. \n",
    "    - In fact, if the decision tree model says class >=50k, the model is likely to predict the opposite ðŸ™ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '<=50K', '<=50K', '<=50K'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.predict(test_l50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03395863, 0.96604137],\n",
       "       [0.2133967 , 0.7866033 ],\n",
       "       [0.22867082, 0.77132918],\n",
       "       [0.88195801, 0.11804199]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.predict_proba(test_g50k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This is the `predict_proba` from logistic regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how well this model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "results[\"Stacking_nocat\"] = mean_std_cross_val_scores(\n",
    "    stacking_model, X_train, y_train, return_train_score=True, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.015 (+/- 0.002)</td>\n",
       "      <td>0.011 (+/- 0.001)</td>\n",
       "      <td>0.632 (+/- 0.008)</td>\n",
       "      <td>0.633 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>3.919 (+/- 0.436)</td>\n",
       "      <td>0.074 (+/- 0.009)</td>\n",
       "      <td>0.850 (+/- 0.005)</td>\n",
       "      <td>0.851 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.542 (+/- 0.199)</td>\n",
       "      <td>0.049 (+/- 0.010)</td>\n",
       "      <td>0.813 (+/- 0.003)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>3.168 (+/- 0.494)</td>\n",
       "      <td>0.206 (+/- 0.015)</td>\n",
       "      <td>0.857 (+/- 0.004)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>7.407 (+/- 1.594)</td>\n",
       "      <td>0.080 (+/- 0.019)</td>\n",
       "      <td>0.870 (+/- 0.003)</td>\n",
       "      <td>0.909 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.407 (+/- 0.020)</td>\n",
       "      <td>0.075 (+/- 0.006)</td>\n",
       "      <td>0.871 (+/- 0.004)</td>\n",
       "      <td>0.892 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>7.460 (+/- 0.421)</td>\n",
       "      <td>0.199 (+/- 0.029)</td>\n",
       "      <td>0.872 (+/- 0.003)</td>\n",
       "      <td>0.900 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting</th>\n",
       "      <td>18.925 (+/- 0.636)</td>\n",
       "      <td>0.663 (+/- 0.081)</td>\n",
       "      <td>0.868 (+/- 0.003)</td>\n",
       "      <td>0.959 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting_ndt</th>\n",
       "      <td>16.971 (+/- 0.467)</td>\n",
       "      <td>0.569 (+/- 0.018)</td>\n",
       "      <td>0.872 (+/- 0.003)</td>\n",
       "      <td>0.922 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_nocat</th>\n",
       "      <td>56.177 (+/- 3.658)</td>\n",
       "      <td>0.351 (+/- 0.011)</td>\n",
       "      <td>0.872 (+/- 0.004)</td>\n",
       "      <td>0.900 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               fit_time         score_time         test_score  \\\n",
       "Dummy                 0.015 (+/- 0.002)  0.011 (+/- 0.001)  0.632 (+/- 0.008)   \n",
       "logistic regression   3.919 (+/- 0.436)  0.074 (+/- 0.009)  0.850 (+/- 0.005)   \n",
       "decision tree         0.542 (+/- 0.199)  0.049 (+/- 0.010)  0.813 (+/- 0.003)   \n",
       "random forest         3.168 (+/- 0.494)  0.206 (+/- 0.015)  0.857 (+/- 0.004)   \n",
       "XGBoost               7.407 (+/- 1.594)  0.080 (+/- 0.019)  0.870 (+/- 0.003)   \n",
       "LightGBM              0.407 (+/- 0.020)  0.075 (+/- 0.006)  0.871 (+/- 0.004)   \n",
       "CatBoost              7.460 (+/- 0.421)  0.199 (+/- 0.029)  0.872 (+/- 0.003)   \n",
       "Voting               18.925 (+/- 0.636)  0.663 (+/- 0.081)  0.868 (+/- 0.003)   \n",
       "Voting_ndt           16.971 (+/- 0.467)  0.569 (+/- 0.018)  0.872 (+/- 0.003)   \n",
       "Stacking_nocat       56.177 (+/- 3.658)  0.351 (+/- 0.011)  0.872 (+/- 0.004)   \n",
       "\n",
       "                           train_score  \n",
       "Dummy                0.633 (+/- 0.003)  \n",
       "logistic regression  0.851 (+/- 0.001)  \n",
       "decision tree        1.000 (+/- 0.000)  \n",
       "random forest        1.000 (+/- 0.000)  \n",
       "XGBoost              0.909 (+/- 0.002)  \n",
       "LightGBM             0.892 (+/- 0.000)  \n",
       "CatBoost             0.900 (+/- 0.001)  \n",
       "Voting               0.959 (+/- 0.001)  \n",
       "Voting_ndt           0.922 (+/- 0.001)  \n",
       "Stacking_nocat       0.900 (+/- 0.007)  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The situation here is a bit mind-boggling.\n",
    "- On each fold of cross-validation it is doing cross-validation.\n",
    "- This is really loops within loops within loops within loops..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We can also try a different final estimator:\n",
    "- Let's `DecisionTreeClassifier` as a final estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "stacking_model_tree = StackingClassifier(\n",
    "    list(classifiers_nocat.items()), final_estimator=DecisionTreeClassifier(max_depth=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not very good. But we can visualize the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stacking_model_tree.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.49.1 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"723pt\" height=\"266pt\"\n",
       " viewBox=\"0.00 0.00 723.00 266.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 262)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-262 719,-262 719,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"428,-258 290,-258 290,-220 428,-220 428,-258\"/>\n",
       "<text text-anchor=\"middle\" x=\"359\" y=\"-242.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">LightGBM &lt;= 0.432</text>\n",
       "<text text-anchor=\"middle\" x=\"359\" y=\"-227.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"347,-184 215,-184 215,-146 347,-146 347,-184\"/>\n",
       "<text text-anchor=\"middle\" x=\"281\" y=\"-168.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">XGBoost &lt;= 0.131</text>\n",
       "<text text-anchor=\"middle\" x=\"281\" y=\"-153.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M339.32,-219.83C329.89,-211.13 318.46,-200.58 308.22,-191.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"310.4,-188.37 300.68,-184.16 305.65,-193.52 310.4,-188.37\"/>\n",
       "<text text-anchor=\"middle\" x=\"301.68\" y=\"-205.44\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"503,-184 371,-184 371,-146 503,-146 503,-184\"/>\n",
       "<text text-anchor=\"middle\" x=\"437\" y=\"-168.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">XGBoost &lt;= 0.799</text>\n",
       "<text text-anchor=\"middle\" x=\"437\" y=\"-153.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M378.68,-219.83C388.11,-211.13 399.54,-200.58 409.78,-191.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"412.35,-193.52 417.32,-184.16 407.6,-188.37 412.35,-193.52\"/>\n",
       "<text text-anchor=\"middle\" x=\"416.32\" y=\"-205.44\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"194,-110 56,-110 56,-72 194,-72 194,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"125\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">LightGBM &lt;= 0.066</text>\n",
       "<text text-anchor=\"middle\" x=\"125\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M241.63,-145.83C220.86,-136.24 195.2,-124.4 173.24,-114.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174.63,-111.05 164.08,-110.04 171.7,-117.41 174.63,-111.05\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"350,-110 212,-110 212,-72 350,-72 350,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"281\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">LightGBM &lt;= 0.254</text>\n",
       "<text text-anchor=\"middle\" x=\"281\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M281,-145.83C281,-138.13 281,-128.97 281,-120.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"284.5,-120.41 281,-110.41 277.5,-120.41 284.5,-120.41\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"72,-36 0,-36 0,0 72,0 72,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"36\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.08,-71.72C90.87,-62.77 77.24,-51.9 65.28,-42.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"67.31,-39.5 57.31,-36 62.95,-44.98 67.31,-39.5\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"162,-36 90,-36 90,0 162,0 162,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"126\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125.26,-71.72C125.37,-63.97 125.5,-54.79 125.62,-46.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"129.12,-46.05 125.76,-36 122.12,-45.95 129.12,-46.05\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"259,-36 187,-36 187,0 259,0 259,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"223\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266.06,-71.72C259.18,-63.29 250.89,-53.15 243.44,-44.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.93,-41.53 236.89,-36 240.51,-45.96 245.93,-41.53\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"349,-36 277,-36 277,0 349,0 349,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"313\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M289.24,-71.72C292.89,-63.63 297.24,-53.97 301.22,-45.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"304.42,-46.56 305.34,-36 298.04,-43.68 304.42,-46.56\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"506,-110 368,-110 368,-72 506,-72 506,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"437\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">LightGBM &lt;= 0.577</text>\n",
       "<text text-anchor=\"middle\" x=\"437\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M437,-145.83C437,-138.13 437,-128.97 437,-120.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"440.5,-120.41 437,-110.41 433.5,-120.41 440.5,-120.41\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"656,-110 524,-110 524,-72 656,-72 656,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"590\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">XGBoost &lt;= 0.917</text>\n",
       "<text text-anchor=\"middle\" x=\"590\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M475.61,-145.83C495.89,-136.29 520.92,-124.51 542.4,-114.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"544.11,-117.46 551.67,-110.04 541.13,-111.13 544.11,-117.46\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"443,-36 371,-36 371,0 443,0 443,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"407\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M429.27,-71.72C425.89,-63.72 421.86,-54.18 418.17,-45.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"421.3,-43.85 414.18,-36 414.85,-46.58 421.3,-43.85\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"533,-36 461,-36 461,0 533,0 533,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"497\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M452.45,-71.72C459.65,-63.2 468.32,-52.94 476.09,-43.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"478.85,-45.9 482.63,-36 473.5,-41.38 478.85,-45.9\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"625,-36 553,-36 553,0 625,0 625,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"589\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M589.74,-71.72C589.63,-63.97 589.5,-54.79 589.38,-46.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"592.88,-45.95 589.24,-36 585.88,-46.05 592.88,-45.95\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"715,-36 643,-36 643,0 715,0 715,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"679\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M612.92,-71.72C624.13,-62.77 637.76,-51.9 649.72,-42.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"652.05,-44.98 657.69,-36 647.69,-39.5 652.05,-44.98\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f931b6dee20>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_tree(list(classifiers_nocat.keys()), stacking_model_tree.final_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### An effective strategy\n",
    "\n",
    "- Randomly generate a bunch of models with different hyperparameter configurations, and then stack all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- What is an advantage of ensembling multiple models as opposed to just choosing one of them?\n",
    "    - You may get a better score.\n",
    "- What is a disadvantage of ensembling multiple models as opposed to just choosing one of them?\n",
    "    - Slower, more code maintenance issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are equivalent regression models for all of these:\n",
    "\n",
    "- `RandomForestClassifier` $\\rightarrow$ [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "- `LGBMClassifier` $\\rightarrow$ [`LGBMRegressor`](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html)\n",
    "- `XGBoostClassifier` $\\rightarrow$ [`XGBoostRegressor`](https://xgboost.readthedocs.io/en/latest/python/python_api.html)\n",
    "- `CatBoostClassifier` $\\rightarrow$ `CatBoostRegressor`\n",
    "- `VotingClassifier` $\\rightarrow$ [`VotingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html)\n",
    "- `StackingClassifier` $\\rightarrow$ [`StackingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary \n",
    "\n",
    "- You have a number of models in your toolbox now.  \n",
    "- Ensembles are usually pretty effective.\n",
    "  - Tree-based models are particularly popular and effective on a wide range of problems. \n",
    "  - But they trade off code complexity and speed for prediction accuracy.\n",
    "  - Don't forget that hyperparameter optimization multiplies the slowness of the code!\n",
    "- Stacking is a bit slower than voting, but generally higher accuracy.\n",
    "  - As a bonus, you get to see the coefficients for each base classifier.\n",
    "- All the above models have equivalent regression models.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Relevant papers\n",
    "\n",
    "- [Fernandez-Delgado et al. 2014](http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf) compared 179 classifiers on 121 datasets:\n",
    "    - First best class of methods was Random Forest and second best class of methods was (RBF) SVMs.\n",
    "\n",
    "- If you like to read original papers [here](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf) is the original paper on Random Forests by Leo Breiman. \n",
    "- [XGBoost, LightGBM or CatBoost â€” which boosting algorithm should I use?](https://medium.com/riskified-technology/xgboost-lightgbm-or-catboost-which-boosting-algorithm-should-i-use-e7fda7bb36bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
